##
## Copyright (c) 2020-2024 BedRock Systems, Inc.
## This software is distributed under the terms of the BedRock Open-Source License.
## See the LICENSE-BedRock file in the repository root for details.
##

################################################
# This file configures the cpp2v CI/CD pipelines.
#
# There are two pipelines:
#
#   1. build_latest -> test_latest
#
#      This builds and tests cpp2v against the current
#      major version of llvm.
#      In fact, "latest" does not depend on the latest version, but on the main
#      supported one.
#
#   2. build_llvmX -> test_llvmX
#
#      This builds cpp2v against an alternate major
#      version of llvm - llvmX. It tests only the cpp2v
#      frontend.
#
# The build* jobs extend the .build template job.
# The test* jobs extend the .test template job.
#
# NOTE: If you need to change the base software in a
# container image used in a pipeline, first update
# Dockerfile and push a new image to the registry
# (see Dockerfile for more information).
################################################

variables:
  LLVM_CUR_MAJ_VER: "16"
  docker_img_prefix: registry.gitlab.com/bedrocksystems/docker-image
  fm_docs_img: ${docker_img_prefix}:fm-docs-coq819
  img_prefix: cpp2v-llvm

# Configs
.base:
  image: ${docker_img_prefix}:${img_prefix}${LLVM_MAJ_VER}-coq819

.latest:
  extends: .base
  variables:
    LLVM_MAJ_VER: ${LLVM_CUR_MAJ_VER}

.llvm17:
  extends: .base
  variables:
    LLVM_MAJ_VER: 17

.llvm18:
  extends: .base
  variables:
    LLVM_MAJ_VER: 18

.public:
  extends: .base
  variables:
    img_prefix: cpp2v-public-llvm
    LLVM_MAJ_VER: ${LLVM_CUR_MAJ_VER}

stages:
  - dune-build
  - build
  - test
  - prepare_pages
  - pages
  - prepare_env_for_downstream
  - build_proofs_downstream

# Include only in the merge request pipeline
.only-mrs:
  rules:
    - if: '$CI_MERGE_REQUEST_LABELS =~ /.*CI-skip-proofs.*/'
      when: never
    - if: $CI_MERGE_REQUEST_IID

.proof-trigger:
  rules:
    - !reference [.only-mrs, rules]

# Include both in the merge request pipeline, and in the pipelines on the default branch
.proof-trigger-mr-releases:
  rules:
    - !reference [.only-mrs, rules]
    - if: $CI_COMMIT_TAG
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH

#This is a template job that's extended below by the real jobs
# build_{latest,llvmNN,public} (see, e.g., https://docs.gitlab.com/ee/ci/yaml/#extends).
.build_base:
  stage: build
  needs: []
  script:
    - mkdir -p build
    - echo "fmdeps/cpp2v-core:$(git rev-parse HEAD)" | tee build/gitshas.txt
    - cd build; cmake ../; cd ..
    - make -j ${NJOBS} cpp2v
    - make -j ${NJOBS} coq
    - rm -f build/bedrock
    - cp -a theories build/bedrock
  artifacts:
    name: cpp2v-${LLVM_MAJ_VER}
    paths:
      - build/gitshas.txt
      - build/cpp2v
      - build/bedrock
  tags:
    - fm.shared

.build:
  extends:
    - .proof-trigger-mr-releases
    - .build_base

.build_aux:
  extends:
    - .proof-trigger
    - .build_base

.test:
  extends:
    - .proof-trigger
  stage: test
  script:
    - coqc -v
    - opam list
    - ./build/cpp2v --cpp2v-version 0 --
    - PATH=$PWD/build:$PATH make test -j ${NJOBS} TIMED=1 QPATH=`pwd`/build/bedrock
  tags:
    - fm.shared

build_latest:
  extends:
    - .public
    - .build
    - .latest

# Ensure that the code builds against dependencies declared in opam files, and
# that those match the versions in our "public" Docker image.
# TODO: This seems to depend on commiting files that dune can generate (`*.opam`).
build_public_opam:
  script:
    - opam pin add -n -y coq-upoly.dev ./coq-upoly
    - opam pin add -n -y coq-cpp2v.dev .
    - opam pin add -n -y coq-cpp2v-bin.dev .
    - opam pin add -n -y coq-lens.dev ./coq-lens
    - opam pin add -n -y coq-lens-elpi.dev ./coq-lens
    - opam install --assume-depexts -y coq-upoly coq-cpp2v coq-cpp2v-bin coq-lens coq-lens-elpi
  needs: [dune-build]
  extends:
    - .build_aux
    - .public
  # No artifacts are needed here.
  artifacts:

prepare_pages:
  extends:
    - .proof-trigger-mr-releases
  image: ${fm_docs_img}
  stage: prepare_pages
  needs:
    - build_latest
  variables:
    LLVM_MAJ_VER: ${LLVM_CUR_MAJ_VER}
  script:
    - sudo chown coq.coq -R .
    # Clone the Alectryon submodule, but only in the pages jobs
    - git submodule update --init
    # Copy compiled code.
    #
    # Beware: the trailing slash affects the semantics.
    # Excluded flags, compared to -a: -pgoD
    # --omit-dir-times because of https://stackoverflow.com/a/668049/53974 and
    # https://gitlab.com/bedrocksystems/cpp2v-core/-/jobs/1474918505#L1325
    # and --omit-link-times to be safe.
    - sudo rsync
        --exclude '*.vok' --exclude '*.vos' --exclude '*.v'
        -avc
        --omit-link-times --omit-dir-times
        build/bedrock/ theories
    - make touch_deps
    - make -j ${NJOBS} doc
  artifacts:
    paths:
      - doc/sphinx/_build
  tags:
    - fm.shared

pages:
  stage: pages
  # Just Gitlab's default.
  # TODO: an even lighter one would work, or maybe we
  # could move this step into prepare_pages somehow?
  image: ruby:2.5
  needs:
    - prepare_pages
  script:
    # Note: we inline the definition of the `make pages` rule to avoid a CI breakage which we
    # encountered when attempting to invoke `make pages` /after/ downloading the doc-artifacts
    # from the `prepare-pages` stage and /without/ pulling the `fm-docs` image.
    #
    # While there is likely a solution which allows us to continue using `make pages` directly,
    # we're taking the easy way out to avoid being nerd-sniped by CI.
    - cp -R doc/sphinx/_build/html public

    # Note: in order to "push" up-to-date documentation to our public github repo /without/
    # muddying [master] we maintain a separate /protected/ branch called [gh-pages]. This branch
    # /will not/ track the actual contents of our repository; it is up for debate whether or not
    # we remove everything besides [brick/doc/]. Instead, every successful publish of the
    # /gitlab/ pages will also commit the new html artifacts to [brick/doc/@gh-pages] (replacing
    # the existing ones). We configure the [gh-pages] branch to be automatically mirrored to
    # github, and we configure github to use [gh-pages] as the branch for the public pages
    # documentation.
    #
    # Note: taken from here <https://forum.gitlab.com/t/is-it-possible-to-commit-artifacts-into-the-git/22218/7>
    - git clone https://${BRICK_BOT_USERNAME}:${BRICK_BOT_TOKEN}@gitlab.com/bedrocksystems/cpp2v-core.git # Clone repo
    - git remote set-url origin https://${BRICK_BOT_USERNAME}:${BRICK_BOT_TOKEN}@gitlab.com/bedrocksystems/cpp2v-core.git # git configuration
    # QUESTION (JH): Are these exposed within the (protected) [master] branch?
    - git config --global user.email "${BRICK_BOT_EMAIL}" && git config --global user.name "${BRICK_BOT_USERNAME}"
    - cd cpp2v-core
    # switch to our protected branch
    - git checkout gh-pages
    # remove the old documentation
    - git rm -r docs/
    # add the new documentation
    - cp -R ../doc/sphinx/_build/html docs && git add -f docs/
    - touch docs/.nojekyll
    - git add docs/.nojekyll
    - git diff-index --quiet HEAD ||
      ( git commit -m "[github pages] BRiCk documentation created from $CI_COMMIT_SHORT_SHA" ;
        git push origin gh-pages )
  rules:
    # Run on master
    - if: '$CI_COMMIT_BRANCH == "master"'
  artifacts:
    paths:
      - public
  tags:
    - fm.shared

prepare_cpp2v_env:
  extends:
    - .latest
    - .proof-trigger-mr-releases
  stage: prepare_env_for_downstream
  needs:
    - dune-build
  script:
    - >
      if [[ $CI_MERGE_REQUEST_LABELS =~ .*CI::same-branch.* ]]; then
        export DOWNSTREAM_BRANCH=$CI_MERGE_REQUEST_SOURCE_BRANCH_NAME;
        git ls-remote --exit-code --heads   https://gitlab-ci-token:${CI_JOB_TOKEN}@gitlab.com/bedrocksystems/cpp2v.git refs/heads/$DOWNSTREAM_BRANCH &&
         export DOWNSTREAM_CPP2V_BRANCH=$DOWNSTREAM_BRANCH ||
         export DOWNSTREAM_CPP2V_BRANCH="master";
      else export DOWNSTREAM_CPP2V_BRANCH="master";
           export DOWNSTREAM_BRANCH="master"; fi
    - if [[ $CI_MERGE_REQUEST_LABELS =~ .*FM-CI-timing.* ]]; then FULL_TIMING=1; else FULL_TIMING=0; fi
    - export CPP2V_CORE_COMMIT_HASH=$(git -C $CI_PROJECT_DIR rev-parse HEAD)
    # Use whatever master commit was merged into our branch as a point of reference.
    # If this is not a merged pipeline use `git merge-base` instead.
    - echo $CPP2V_CORE_COMMIT_REF_HASH
    - echo $CI_MERGE_REQUEST_LABELS
    - >
      if [[ $CI_MERGE_REQUEST_LABELS =~ .*FM-CI-Compare.* ]]; then
        echo "LABEL MATCH"
        if [[ -z "$CI_MERGE_REQUEST_TARGET_BRANCH_SHA" ]]; then
          echo "TARGET BRANCH"
          # Only possible on manually triggered pipelines
          export CPP2V_CORE_COMMIT_REF_HASH=$(git merge-base origin/master HEAD);
        else
          echo "NO TARGET BRANCH"
          export CPP2V_CORE_COMMIT_REF_HASH=$CI_MERGE_REQUEST_TARGET_BRANCH_SHA;
        fi
      fi
    - echo $CPP2V_CORE_COMMIT_REF_HASH
    - echo "DOWNSTREAM_CPP2V_BRANCH=$DOWNSTREAM_CPP2V_BRANCH" >> build.env
    - echo "DOWNSTREAM_BRANCH=$DOWNSTREAM_BRANCH" >> build.env
    - echo "CPP2V_CORE_COMMIT_HASH=$CPP2V_CORE_COMMIT_HASH" >> build.env
    - echo "CPP2V_CORE_COMMIT_REF_HASH=$CPP2V_CORE_COMMIT_REF_HASH" >> build.env
    - echo "FULL_TIMING=$FULL_TIMING" >> build.env
    # TODO remove eventually; only for legacy builds
    - echo "ARTIFACT_JOB_ID=$ARTIFACT_JOB_ID" >> build.env
    - cat build.env
  artifacts:
    reports:
      dotenv: build.env
  tags:
    - fm.shared

.setup-dunecache:
  stage: dune-build
  variables:
    DUNE_CACHE: enabled
    DUNE_CACHE_STORAGE_MODE: copy
  before_script:
    - git clone --depth 1 https://gitlab-ci-token:${CI_JOB_TOKEN}@gitlab.com/bedrocksystems/fm-ci-tools.git
    - cat ./fm-ci-tools/fm_dune/build_env_dune.inc.sh
    - source ./fm-ci-tools/fm_dune/build_env_dune.inc.sh
    - ./fm-ci-tools/fm_dune/filter_build_env_dune.sh >> build.env
    # Lock cache only on Sundays(cache cleanup day)
    - >
      if [[ `date +%u` -eq 7 ]] ; then
        for i in {1..3}; do
          time ./fm-ci-tools/fm_dune/dune_lock_ci.py check_cleanup_job -t ${GRP_CI_TOKEN} -v RSYNC_PUSH -a build.env && break
        done
      fi
    # Workaround for https://github.com/ocaml/dune/issues/6005: we must ensure
    # that we run dune in bhv-shaped workspaces, since cache entries are keyed
    # on relative paths from the workspace root.
    - mkdir -p /tmp/build-dir/fmdeps/
    - cp -ra $CI_PROJECT_DIR /tmp/build-dir/fmdeps/cpp2v-core
    - cp $CI_PROJECT_DIR/dune-ci/root-dune-project /tmp/build-dir/dune-project
    # Set up the cache and dune configuration.
    - mkdir -p ~/.cache/ ~/.config/dune/
    - ls ~/.cache/dune
    - cp $CI_PROJECT_DIR/dune-ci/dune_config ~/.config/dune/config

.postupdate-dunecache:
  after_script:
    - source build.env
    - cat build.env

.dune-base:
  extends:
    - .setup-dunecache
    - .postupdate-dunecache
  stage: dune-build
  variables:
    CODEQ_LOG: ${CI_PROJECT_DIR}/dune_build_codeq.log
  tags:
    - fm.nfs

.dune-build-base:
  extends:
    - .dune-base
  script:
    # Create the directory for the artifact, and write the Git sha.
    # -p because it might exist because of artifacts we depend on.
    - mkdir -p build
    - echo "fmdeps/cpp2v-core:$(git rev-parse HEAD)" | tee build/gitshas.txt
    # Set up the environment and run the build (in the prepared workspace).
    - cd /tmp/build-dir/fmdeps/cpp2v-core
    - time dune build -j ${NJOBS} . coq-lens/coq-lens.install coq-lens/coq-lens-elpi.install 2>&1 | ocaml ./fm-ci-tools/fm_dune/filter_dune_output.ml | tee -a ${CODEQ_LOG}
    - time dune build -j ${NJOBS} . coq-cpp2v.install coq-cpp2v-bin.install 2>&1 | ocaml ./fm-ci-tools/fm_dune/filter_dune_output.ml | tee -a ${CODEQ_LOG}
    - time dune build -j ${NJOBS} -p coq-upoly,coq-lens,coq-lens-elpi,coq-cpp2v,coq-cpp2v-bin 2>&1 | ocaml ./fm-ci-tools/fm_dune/filter_dune_output.ml | tee -a ${CODEQ_LOG}
    - cd $CI_PROJECT_DIR/
    # ARTIFACT_JOB_ID is used for downstream jobs to get artifacts from
    # this build. The value of CI_JOB_ID is only available in this
    # build_latest job, so it has to be stored here.
    - echo "ARTIFACT_JOB_ID=$CI_JOB_ID" >> build.env
    - time ./fm-ci-tools/code_quality.py cpp2v-core || true
  artifacts:
    reports:
      dotenv: build.env
      codequality: gl-code-quality-report.json
    name: cpp2v-${LLVM_MAJ_VER}
    paths:
      - build/gitshas.txt
      - gl-code-quality-report.json
      - dune_build_codeq.log

.dune-build:
  stage: dune-build
  needs: []
  extends:
    - .dune-build-base
    - .proof-trigger-mr-releases

.dune-build-aux:
  stage: build
  needs: [dune-build]
  extends:
    - .dune-build-base
    - .proof-trigger

.dune-test-base:
  stage: test
  extends:
    - .dune-base
  script:
    # Set up the environment and run the build (in the prepared workspace).
    - cd /tmp/build-dir/fmdeps/cpp2v-core
    - >
      (time dune runtest -j ${NJOBS} 2>&1 || (echo "Error: cram tests failed" && exit 1)) | ocaml ./fm-ci-tools/fm_dune/filter_dune_output.ml | tee -a ${CODEQ_LOG}
    - cd $CI_PROJECT_DIR/
    - time ./fm-ci-tools/code_quality.py cpp2v-core || true
  artifacts:
    reports:
      codequality: gl-code-quality-report.json
    paths:
      - gl-code-quality-report.json
      - dune_build_codeq.log

.dune-test:
  extends:
    - .dune-test-base
    - .proof-trigger-mr-releases

.dune-test-aux:
  extends:
    - .dune-test-base
    - .proof-trigger

# Actual build/test matrix

dune-build:
  extends:
    - .dune-build
    - .latest

dune-build-llvm17:
  extends:
    - .dune-build-aux
    - .llvm17

#dune-build-llvm18:
#  extends:
#    - .dune-build-aux
#    - .llvm18

# TODO FM-4156 Reenable
# dune-build-public:
#   extends:
#     - .dune-build-aux
#     - .public

dune-test:
  extends:
    - .dune-test
    - .latest
  needs:
    - dune-build

dune-test-llvm17:
  extends:
    - .dune-test-aux
    - .llvm17
  needs:
    - dune-build-llvm17

#dune-test-llvm18:
#  extends:
#    - .dune-test-aux
#    - .llvm18
#  needs:
#    - dune-build-llvm18

# TODO FM-4156 Reenable
# dune-test-public:
#   extends:
#     - .dune-test-aux
#     - .public
#   needs:
#     - dune-build-public

build-cpp2v-trigger:
  rules:
    - !reference [.proof-trigger-mr-releases, rules]
  # Equivalent to `extends: [.proof-trigger-mr-releases]`,
  # but here we can add more rules.
  stage: build_proofs_downstream
  needs:
    - prepare_cpp2v_env
  variables:
    UPSTREAM_CPP2V_CORE_COMMIT_HASH: $CPP2V_CORE_COMMIT_HASH
    UPSTREAM_CPP2V_CORE_COMMIT_REF_HASH: $CPP2V_CORE_COMMIT_REF_HASH
    DOWNSTREAM_BRANCH: $DOWNSTREAM_BRANCH
    FULL_TIMING: $FULL_TIMING
    ORIGIN_MERGE_REQUEST_PROJECT_ID: $CI_MERGE_REQUEST_PROJECT_ID
    ORIGIN_MERGE_REQUEST_IID: $CI_MERGE_REQUEST_IID
    ORIGIN_MERGE_REQUEST_PIPELINE_URL: $CI_PIPELINE_URL
    # TODO remove eventually; only for legacy builds
    UPSTREAM_CPP2V_CORE_JOB_ID: $ARTIFACT_JOB_ID
  trigger:
    project: bedrocksystems/cpp2v
    branch: $DOWNSTREAM_CPP2V_BRANCH
    strategy: depend
