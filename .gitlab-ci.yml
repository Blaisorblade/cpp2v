##
## Copyright (c) 2020-2024 BedRock Systems, Inc.
## This software is distributed under the terms of the BedRock Open-Source License.
## See the LICENSE-BedRock file in the repository root for details.
##

################################################
# This file configures the cpp2v CI/CD pipelines.
#
# NOTE: If you need to change the base software in a
# container image used in a pipeline, first update
# Dockerfile and push a new image to the registry
# (see Dockerfile for more information).
################################################

variables:
  LLVM_CUR_MAJ_VER: "16"
  docker_img_prefix: registry.gitlab.com/bedrocksystems/docker-image
  fm_docs_img: ${docker_img_prefix}:fm-docs-coq819
  img_prefix: cpp2v-llvm
  BUILD_DIR: /tmp/build-dir
  FMDEPS_DIR: $BUILD_DIR/fmdeps
  FM_CI_TOOLS: $FMDEPS_DIR/fm-ci-tools

# Configs
.base:
  image: ${docker_img_prefix}:${img_prefix}${LLVM_MAJ_VER}-coq819

.latest:
  extends: .base
  variables:
    LLVM_MAJ_VER: ${LLVM_CUR_MAJ_VER}

.llvm17:
  extends: .base
  variables:
    LLVM_MAJ_VER: 17

.llvm18:
  extends: .base
  variables:
    LLVM_MAJ_VER: 18

.public:
  extends: .base
  variables:
    img_prefix: cpp2v-public-llvm
    LLVM_MAJ_VER: ${LLVM_CUR_MAJ_VER}

stages:
  - dune-build
  - build
  - test
  - prepare_pages
  - pages
  - prepare_env_for_downstream
  - build_proofs_downstream

# Name not accurate anymore.
.only-mrs:
  rules:
    - if: '$CI_MERGE_REQUEST_LABELS =~ /.*CI-skip-proofs.*/'
      when: never
    - if: '$CI_PIPELINE_SOURCE =~ /^(push)$/ && $CI_COMMIT_BRANCH && $CI_COMMIT_REF_NAME != "master"'
      when: never
    - if: '$CI_PIPELINE_SOURCE =~ /^(api|chat|external|external_pull_request_event)$/'
      when: never

.proof-trigger:
  rules:
    - !reference [.only-mrs, rules]
    - when: on_success

# Include both in the merge request pipeline, and in the pipelines on the default branch
.proof-trigger-mr-releases:
  rules:
    - !reference [.only-mrs, rules]
    - if: $CI_COMMIT_TAG
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
    - when: on_success

# Ensure that the code builds against dependencies declared in opam files, and
# that those match the versions in our "public" Docker image.
# TODO: This seems to depend on commiting files that dune can generate (`*.opam`).
build_public_opam:
  stage: build
  tags:
    - fm.shared
  script:
    - opam pin add -n -y coq-upoly.dev ./coq-upoly
    - opam pin add -n -y coq-cpp2v.dev .
    - opam pin add -n -y coq-cpp2v-bin.dev .
    - opam pin add -n -y coq-lens.dev ./coq-lens
    - opam pin add -n -y coq-lens-elpi.dev ./coq-lens
    - opam install --assume-depexts -y coq-upoly coq-cpp2v coq-cpp2v-bin coq-lens coq-lens-elpi
  needs: [dune-build]
  extends:
    - .proof-trigger
    - .public
  # No artifacts are needed here.
  artifacts:

prepare_pages:
  extends:
    - .proof-trigger-mr-releases
  image: ${fm_docs_img}
  stage: prepare_pages
  needs:
    - [dune-build]
  variables:
    LLVM_MAJ_VER: ${LLVM_CUR_MAJ_VER}
  script:
    - sudo chown coq:coq -R .
    # Clone the Alectryon submodule, but only in the pages jobs
    - git submodule update --init
    - opam install -y odoc
    - make -j ${NJOBS} doc BUILD_ROOT=_build/default
  artifacts:
    paths:
      - doc/sphinx/_build
  tags:
    - fm.shared

pages:
  stage: pages
  # Just Gitlab's default.
  # TODO: an even lighter one would work, or maybe we
  # could move this step into prepare_pages somehow?
  image: ruby:2.5
  needs:
    - prepare_pages
  script:
    # Note: we inline the definition of the `make pages` rule to avoid a CI breakage which we
    # encountered when attempting to invoke `make pages` /after/ downloading the doc-artifacts
    # from the `prepare-pages` stage and /without/ pulling the `fm-docs` image.
    #
    # While there is likely a solution which allows us to continue using `make pages` directly,
    # we're taking the easy way out to avoid being nerd-sniped by CI.
    - cp -R doc/sphinx/_build/html public

    # Note: in order to "push" up-to-date documentation to our public github repo /without/
    # muddying [master] we maintain a separate /protected/ branch called [gh-pages]. This branch
    # /will not/ track the actual contents of our repository; it is up for debate whether or not
    # we remove everything besides [brick/doc/]. Instead, every successful publish of the
    # /gitlab/ pages will also commit the new html artifacts to [brick/doc/@gh-pages] (replacing
    # the existing ones). We configure the [gh-pages] branch to be automatically mirrored to
    # github, and we configure github to use [gh-pages] as the branch for the public pages
    # documentation.
    #
    # Note: taken from here <https://forum.gitlab.com/t/is-it-possible-to-commit-artifacts-into-the-git/22218/7>
    - git clone https://${BRICK_BOT_USERNAME}:${BRICK_BOT_TOKEN}@gitlab.com/bedrocksystems/cpp2v-core.git # Clone repo
    - git remote set-url origin https://${BRICK_BOT_USERNAME}:${BRICK_BOT_TOKEN}@gitlab.com/bedrocksystems/cpp2v-core.git # git configuration
    # QUESTION (JH): Are these exposed within the (protected) [master] branch?
    - git config --global user.email "${BRICK_BOT_EMAIL}" && git config --global user.name "${BRICK_BOT_USERNAME}"
    - cd cpp2v-core
    # switch to our protected branch
    - git checkout gh-pages
    # remove the old documentation
    - git rm -r docs/
    # add the new documentation
    - cp -R ../doc/sphinx/_build/html docs && git add -f docs/
    - touch docs/.nojekyll
    - git add docs/.nojekyll
    - git diff-index --quiet HEAD ||
      ( git commit -m "[github pages] BRiCk documentation created from $CI_COMMIT_SHORT_SHA" ;
        git push origin gh-pages )
  rules:
    # Run on master
    - if: '$CI_COMMIT_BRANCH == "master"'
  artifacts:
    paths:
      - public
  tags:
    - fm.shared

prepare_cpp2v_env:
  extends:
    - .latest
    - .proof-trigger-mr-releases
  stage: prepare_env_for_downstream
  needs:
    - dune-build
  script:
    - >
      if [[ $CI_MERGE_REQUEST_LABELS =~ .*CI::same-branch.* ]]; then
        export DOWNSTREAM_BRANCH=$CI_MERGE_REQUEST_SOURCE_BRANCH_NAME
      elif [[ -n $DOWNSTREAM_BRANCH ]] && [[ $DOWNSTREAM_BRANCH != "master" ]]; then
        export DOWNSTREAM_BRANCH
      else
        export DOWNSTREAM_BRANCH="master"
      fi
    - echo "DOWNSTREAM_BRANCH=$DOWNSTREAM_BRANCH"
    - >
      if git ls-remote --exit-code --heads https://gitlab-ci-token:${CI_JOB_TOKEN}@gitlab.com/bedrocksystems/cpp2v.git refs/heads/$DOWNSTREAM_BRANCH; then
        export DOWNSTREAM_CPP2V_BRANCH=$DOWNSTREAM_BRANCH
      else
        export DOWNSTREAM_CPP2V_BRANCH="master"
      fi
    - if [[ $CI_MERGE_REQUEST_LABELS =~ .*FM-CI-timing.* ]]; then FULL_TIMING=1; else FULL_TIMING=0; fi
    - export CPP2V_CORE_COMMIT_HASH=$(git -C $CI_PROJECT_DIR rev-parse HEAD)
    # Use whatever master commit was merged into our branch as a point of reference.
    # If this is not a merged pipeline use `git merge-base` instead.
    - echo $CPP2V_CORE_COMMIT_REF_HASH
    - echo $CI_MERGE_REQUEST_LABELS
    - >
      if [[ $CI_MERGE_REQUEST_LABELS =~ .*FM-CI-Compare.* ]] || [[ -n "$UPSTREAM_FM_CI_TOOLS_COMMIT_REF_HASH" ]]; then
        echo "LABEL MATCH"
        if [[ -z "$CI_MERGE_REQUEST_TARGET_BRANCH_SHA" ]]; then
          # Usual reason: MR cannot be merged right now due to conflicts.
          echo "NO TARGET BRANCH"
          export CPP2V_CORE_COMMIT_REF_HASH=$(git merge-base origin/master HEAD);
        else
          echo "TARGET BRANCH"
          export CPP2V_CORE_COMMIT_REF_HASH=$CI_MERGE_REQUEST_TARGET_BRANCH_SHA;
        fi
      fi
    - >
      if [[ -z "$ORIGIN_MERGE_REQUEST_PROJECT_ID" ]]; then
        export ORIGIN_MERGE_REQUEST_PROJECT_ID=$CI_MERGE_REQUEST_PROJECT_ID
        export ORIGIN_MERGE_REQUEST_IID=$CI_MERGE_REQUEST_IID
        export ORIGIN_MERGE_REQUEST_PIPELINE_URL=$CI_PIPELINE_URL
      fi
    - echo "DOWNSTREAM_CPP2V_BRANCH=$DOWNSTREAM_CPP2V_BRANCH" >> build.env
    - echo "DOWNSTREAM_BRANCH=$DOWNSTREAM_BRANCH" >> build.env
    - echo "CPP2V_CORE_COMMIT_HASH=$CPP2V_CORE_COMMIT_HASH" >> build.env
    - echo "CPP2V_CORE_COMMIT_REF_HASH=$CPP2V_CORE_COMMIT_REF_HASH" >> build.env
    - echo "UPSTREAM_FM_CI_TOOLS_COMMIT_HASH=$UPSTREAM_FM_CI_TOOLS_COMMIT_HASH" >> build.env
    - echo "UPSTREAM_FM_CI_TOOLS_COMMIT_REF_HASH=$UPSTREAM_FM_CI_TOOLS_COMMIT_REF_HASH" >> build.env
    - echo "FULL_TIMING=$FULL_TIMING" >> build.env
    - echo "ORIGIN_MERGE_REQUEST_PROJECT_ID=$ORIGIN_MERGE_REQUEST_PROJECT_ID" >> build.env
    - echo "ORIGIN_MERGE_REQUEST_IID=$ORIGIN_MERGE_REQUEST_IID" >> build.env
    - echo "ORIGIN_MERGE_REQUEST_PIPELINE_URL=$ORIGIN_MERGE_REQUEST_PIPELINE_URL" >> build.env
    # TODO remove eventually; only for legacy builds
    - echo "ARTIFACT_JOB_ID=$ARTIFACT_JOB_ID" >> build.env
    - cat build.env
  artifacts:
    reports:
      dotenv: build.env
  tags:
    - fm.shared

.checkout_fm_ci_tools: &checkout_fm_ci_tools
  - git clone --depth 1 https://gitlab-ci-token:${CI_JOB_TOKEN}@gitlab.com/bedrocksystems/fm-ci-tools.git ${FMDEPS_DIR}/fm-ci-tools
  - >
    if [[ -n $UPSTREAM_FM_CI_TOOLS_COMMIT_HASH ]]; then
      # Specific commit specified upstream.
      git -C ${FMDEPS_DIR}/fm-ci-tools fetch origin $UPSTREAM_FM_CI_TOOLS_COMMIT_HASH
      git -C ${FMDEPS_DIR}/fm-ci-tools checkout $UPSTREAM_FM_CI_TOOLS_COMMIT_HASH
    else
      export UPSTREAM_FM_CI_TOOLS_COMMIT_HASH=$(git -C ${FMDEPS_DIR}/fm-ci-tools rev-parse HEAD)
    fi
  - echo "UPSTREAM_FM_CI_TOOLS_COMMIT_HASH=$UPSTREAM_FM_CI_TOOLS_COMMIT_HASH" >> build.env
  - echo "UPSTREAM_FM_CI_TOOLS_COMMIT_REF_HASH=$UPSTREAM_FM_CI_TOOLS_COMMIT_REF_HASH" >> build.env

.setup-dunecache:
  stage: dune-build
  variables:
    DUNE_CACHE: enabled
    DUNE_CACHE_STORAGE_MODE: copy
  before_script:
    - *checkout_fm_ci_tools
    - echo "DOWNSTREAM_BRANCH=$DOWNSTREAM_BRANCH" >> build.env
    - cat $FM_CI_TOOLS/fm_dune/build_env_dune.inc.sh
    - source $FM_CI_TOOLS/fm_dune/build_env_dune.inc.sh
    - $FM_CI_TOOLS/fm_dune/filter_build_env_dune.sh >> build.env
    # Lock cache only on Sundays(cache cleanup day)
    - >
      if [[ `date +%u` -eq 7 ]] ; then
        for i in {1..3}; do
          time $FM_CI_TOOLS/fm_dune/dune_lock_ci.py check_cleanup_job -t ${GRP_CI_TOKEN} -v RSYNC_PUSH -a build.env && break
        done
      fi
    # Workaround for https://github.com/ocaml/dune/issues/6005: we must ensure
    # that we run dune in bhv-shaped workspaces, since cache entries are keyed
    # on relative paths from the workspace root.
    - mkdir -p $FMDEPS_DIR
    - cp -ra $CI_PROJECT_DIR $FMDEPS_DIR/cpp2v-core
    - cp $CI_PROJECT_DIR/dune-ci/root-dune-project $BUILD_DIR/dune-project
    # Set up the cache and dune configuration.
    - mkdir -p ~/.cache/ ~/.config/dune/
    - ls ~/.cache/dune
    - cp $CI_PROJECT_DIR/dune-ci/dune_config ~/.config/dune/config

.postupdate-dunecache:
  after_script:
    - source build.env
    - cat build.env

.dune-base:
  extends:
    - .setup-dunecache
    - .postupdate-dunecache
  stage: dune-build
  variables:
    CODEQ_LOG: ${CI_PROJECT_DIR}/dune_build_codeq.log
  tags:
    - fm.nfs

.dune-build-base:
  extends:
    - .dune-base
  script:
    # Create the directory for the artifact, and write the Git sha.
    # -p because it might exist because of artifacts we depend on.
    - mkdir -p build
    - echo "fmdeps/cpp2v-core:$(git rev-parse HEAD)" | tee build/gitshas.txt
    # Set up the environment and run the build (in the prepared workspace).
    - cd $FMDEPS_DIR/cpp2v-core
    - time dune build -j ${NJOBS} . coq-lens/coq-lens.install coq-lens/coq-lens-elpi.install 2>&1 | ocaml $FM_CI_TOOLS/fm_dune/filter_dune_output.ml | tee -a ${CODEQ_LOG}
    - time dune build -j ${NJOBS} . coq-cpp2v.install coq-cpp2v-bin.install 2>&1 | ocaml $FM_CI_TOOLS/fm_dune/filter_dune_output.ml | tee -a ${CODEQ_LOG}
    - time dune build -j ${NJOBS} -p coq-upoly,coq-lens,coq-lens-elpi,coq-cpp2v,coq-cpp2v-bin 2>&1 | ocaml $FM_CI_TOOLS/fm_dune/filter_dune_output.ml | tee -a ${CODEQ_LOG}
    - cd $CI_PROJECT_DIR/
    # ARTIFACT_JOB_ID is used for downstream jobs to get artifacts from
    # this build. The value of CI_JOB_ID is only available in this
    # build_latest job, so it has to be stored here.
    - echo "ARTIFACT_JOB_ID=$CI_JOB_ID" >> build.env
    - time $FM_CI_TOOLS/code_quality.py cpp2v-core || true
  artifacts:
    reports:
      dotenv: build.env
      codequality: gl-code-quality-report.json
    name: cpp2v-${LLVM_MAJ_VER}
    paths:
      - build/gitshas.txt
      - gl-code-quality-report.json
      - dune_build_codeq.log

.dune-build:
  stage: dune-build
  needs: []
  extends:
    - .dune-build-base
    - .proof-trigger-mr-releases

.dune-build-aux:
  stage: build
  needs: [dune-build]
  extends:
    - .dune-build-base
    - .proof-trigger

.dune-test-base:
  stage: test
  extends:
    - .dune-base
  script:
    # Set up the environment and run the build (in the prepared workspace).
    - cd $FMDEPS_DIR/cpp2v-core
    - >
      (time dune runtest -j ${NJOBS} 2>&1 || (echo "Error: cram tests failed" && exit 1)) | ocaml $FM_CI_TOOLS/fm_dune/filter_dune_output.ml | tee -a ${CODEQ_LOG}
    - cd $CI_PROJECT_DIR/
    - time $FM_CI_TOOLS/code_quality.py cpp2v-core || true
  artifacts:
    reports:
      codequality: gl-code-quality-report.json
    paths:
      - gl-code-quality-report.json
      - dune_build_codeq.log

.dune-test:
  extends:
    - .dune-test-base
    - .proof-trigger-mr-releases

.dune-test-aux:
  extends:
    - .dune-test-base
    - .proof-trigger

# Actual build/test matrix

dune-build:
  extends:
    - .dune-build
    - .latest

dune-build-llvm17:
  extends:
    - .dune-build-aux
    - .llvm17

dune-build-llvm18:
  extends:
    - .dune-build-aux
    - .llvm18

# TODO FM-4156 Reenable
# dune-build-public:
#   extends:
#     - .dune-build-aux
#     - .public

dune-test:
  extends:
    - .dune-test
    - .latest
  needs:
    - dune-build

dune-test-llvm17:
  extends:
    - .dune-test-aux
    - .llvm17
  needs:
    - dune-build-llvm17

dune-test-llvm18:
  extends:
    - .dune-test-aux
    - .llvm18
  needs:
    - dune-build-llvm18

# TODO FM-4156 Reenable
# dune-test-public:
#   extends:
#     - .dune-test-aux
#     - .public
#   needs:
#     - dune-build-public

build-cpp2v-trigger:
  rules:
    - !reference [.proof-trigger-mr-releases, rules]
  # Equivalent to `extends: [.proof-trigger-mr-releases]`,
  # but here we can add more rules.
  stage: build_proofs_downstream
  needs:
    - prepare_cpp2v_env
  variables:
    UPSTREAM_CPP2V_CORE_COMMIT_HASH: $CPP2V_CORE_COMMIT_HASH
    UPSTREAM_CPP2V_CORE_COMMIT_REF_HASH: $CPP2V_CORE_COMMIT_REF_HASH
    UPSTREAM_FM_CI_TOOLS_COMMIT_HASH: $UPSTREAM_FM_CI_TOOLS_COMMIT_HASH
    UPSTREAM_FM_CI_TOOLS_COMMIT_REF_HASH: $UPSTREAM_FM_CI_TOOLS_COMMIT_REF_HASH
    DOWNSTREAM_BRANCH: $DOWNSTREAM_BRANCH
    FULL_TIMING: $FULL_TIMING
    ORIGIN_MERGE_REQUEST_PROJECT_ID: $ORIGIN_MERGE_REQUEST_PROJECT_ID
    ORIGIN_MERGE_REQUEST_IID: $ORIGIN_MERGE_REQUEST_IID
    ORIGIN_MERGE_REQUEST_PIPELINE_URL: $ORIGIN_MERGE_REQUEST_PIPELINE_URL
    # TODO remove eventually; only for legacy builds
    UPSTREAM_CPP2V_CORE_JOB_ID: $ARTIFACT_JOB_ID
  trigger:
    project: bedrocksystems/cpp2v
    branch: $DOWNSTREAM_CPP2V_BRANCH
    strategy: depend
